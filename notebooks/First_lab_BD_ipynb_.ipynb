{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "6aac9c5b",
      "metadata": {
        "id": "6aac9c5b"
      },
      "source": [
        "<table align=\"center\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/labrijisaad/Twitter-Sentiment-Analysis-with-Python/blob/main/Twitter%20Sentiment%20Analysis%20with%20Python.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
        "  </td>\n",
        "</table>\n",
        "\n",
        "<table align=\"center\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://drive.google.com/file/d/19IeqXU96-kDt6wy1wTNyhWrIw1jbK2Kx/view?usp=sharing\"><img/>Download the dataset</a>\n",
        "  </td>\n",
        "</table>\n",
        "\n",
        "Notebook realised by  [@labriji_saad](https://github.com/labrijisaad) with the help of [analyticsvidhya](https://www.analyticsvidhya.com/)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "15ebd4f1",
      "metadata": {
        "id": "15ebd4f1"
      },
      "source": [
        "## ðŸ”° `Introduction` :\n",
        "\n",
        ">**Sentiment analysis** refers to `identifying as well as classifying the sentiments` that are expressed in the text source. Tweets are often useful in generating a vast amount of sentiment data upon analysis. These data are useful in understanding the opinion of the people about a variety of topics.\n",
        "\n",
        ">Therefore we need to develop an **Automated Machine Learning Sentiment Analysis Model** in order to `compute the customer perception`. Due to the presence of non-useful characters (collectively termed as the noise) along with useful data, it becomes difficult to implement models on them."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7f79b6b3",
      "metadata": {
        "id": "7f79b6b3"
      },
      "source": [
        "## ðŸŽ¯  `Objective` :\n",
        "\n",
        ">We aim to analyze the sentiment of the tweets provided from the `Sentiment140 dataset` by developing a **`machine learning pipeline`** involving the use of three classifiers:\n",
        "> - **`Logistic Regression`**.\n",
        "> - **`Bernoulli Naive Bayes`**.\n",
        "> - **`SVM`**.  <br>                                                           \n",
        "Along with using **`Term Frequency- Inverse Document Frequency (TF-IDF)`**. \n",
        "\n",
        ">The **performance** of these classifiers is then **evaluated** using **accuracy**, **ROC-AUC Curve** and **F1 Scores**."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "790c2d2b",
      "metadata": {
        "id": "790c2d2b"
      },
      "source": [
        "## â“ `Some explanations` :\n",
        "> What is **`Logistic Regression ?`** <br>\n",
        "> - **Logistic regression** is a `statistical analysis method` to predict a binary outcome, such as yes or no, based on prior observations of a data set. It is used in statistical software to `understand the relationship between the dependent variable and one or more independent variables` by estimating probabilities using a logistic regression equation. \n",
        "> - **Logistic regression** is `used when your Y variable can take only two values, and if the data is linearly separable`, it is more efficient to classify it into two seperate classes.\n",
        "\n",
        "> What is **`Bernoulli Naive Bayes ?`** <br>\n",
        "> - **Bernoulli Naive Bayes** implements the naive Bayes training and classification algorithms for data that is distributed according to multivariate Bernoulli distributions.\n",
        "> - **Bernoulli Naive Bayes** is one of the variants of the Naive Bayes algorithm in machine learning. It is very useful to be used when the dataset is in a binary distribution where the output label is either present or absent.\n",
        "\n",
        "> What is **`SVM ?`** <br>\n",
        "> - **Support Vector Machine** is a supervised machine learning algorithm used for both classification and regression. Though we say regression problems as well its best suited for classification. The objective of SVM algorithm is to find a hyperplane in an N-dimensional space that distinctly classifies the data points.\n",
        "> - **Support vector machines** are a set of supervised learning methods used for classification, regression and outliers detection. The advantages of support vector machines are: Effective in high dimensional spaces. Still effective in cases where number of dimensions is greater than the number of samples.\n",
        "\n",
        "> What is **`Term Frequency- Inverse Document Frequency (TF-IDF) ?`** <br>\n",
        "> - **Term Frequency** gives us information on how often a term appears in a document.\n",
        "> - **Inverse Document Frequency** is a measure of whether a term is common or rare in a given document corpus.\n",
        "\n",
        "> What is **`Stemming and lemmatization ?`** <br>\n",
        "> - The goal of both  **`stemming`** and  **`lemmatization`** is to reduce inflectional forms and sometimes derivationally related forms of a word to a common base form. \n",
        ">- For instance:\n",
        ">  - **`am`**, **`are`**, **`is`** $\\Rightarrow$ **`be`**\n",
        ">  - **`car`**, **`cars`**, **`car's`**, **`cars'`** $\\Rightarrow$ **`car`**\n",
        "The result of this mapping of text will be something like:\n",
        ">  - `the boy's cars are different colors` $\\Rightarrow$\n",
        "`the boy car be differ color`\n",
        "\n",
        "\n",
        "\n",
        "> How do we **`evaluate our model ?`** <br>\n",
        "> - After training the model we then apply the evaluation measures to check how the model is performing. Accordingly, we use the following evaluation parameters to check the performance of the models respectively :\n",
        "> - **`Accuracy Score`** : Typically, the accuracy of a predictive model is good (above 90% accuracy)\n",
        "> - **`Execution time`** : Variable that depends on the machine on which the program was executed, but which can give a small idea of the model that executes the fastest.\n",
        "> - **`F1 score`** : The F1 score is a weighted harmonic mean of precision and recall such that `the best score is 1.0` and `the worst is 0.0`. **F1 scores are lower than accuracy measures** as they embed precision and recall into their computation.\n",
        "\n",
        "\n",
        "\n",
        "> - **`ROC-AUC Curve`** : The Area Under the Curve (AUC) is the measure of the ability of a classifier to distinguish between classes and is used as a summary of the ROC curve. The higher the AUC, the better the performance of the model at distinguishing between the positive and negative classes.\n",
        "> - **`Confusion Matrix with Plot`** : A Confusion matrix is an N x N matrix used for evaluating the performance of a classification model, where N is the number of target classes. The matrix compares the actual target values with those predicted by the machine learning model. Note that :\n",
        "    * **`Actual values`** are the columns.\n",
        "    * **`Predicted values`** are the lines.\n",
        "><table>\n",
        "    <tbody>\n",
        "        <tr>\n",
        "            <td></td>\n",
        "            <td><b>Positive</b></td>\n",
        "            <td><b>Negative</b></td>\n",
        "        </tr>\n",
        "        <tr>\n",
        "            <td><b>Positive</b></td>\n",
        "            <td>TP</td>\n",
        "            <td>TN</td>\n",
        "        </tr>\n",
        "        <tr>\n",
        "            <td><b>Negative</b></td>\n",
        "            <td>FP</td>\n",
        "            <td>TN</td>\n",
        "        </tr>\n",
        "    </tbody>\n",
        "</table>\n",
        "\n",
        "\n",
        "> What is **`word_tokenize() ?`** <br>\n",
        "> - **Tokenization** is the act of breaking up a sequence of strings into pieces such as words, keywords, phrases, symbols and other elements called tokens.\n",
        "> - **`word_tokenize()`** method. It actually returns the syllables from a single word. A single word can contain one or two syllables. **Return** : Return the list of syllables of words."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1e4965f8",
      "metadata": {
        "id": "1e4965f8"
      },
      "source": [
        "## ðŸ“š `Project Pipeline` :\n",
        ">The various steps involved in the Machine Learning Pipeline are :\n",
        "> - **1ï¸âƒ£ `Import Necessary Dependencies`**.\n",
        "\n",
        "> - **2ï¸âƒ£ `Read and Load the Dataset`**.\n",
        "\n",
        "> - **3ï¸âƒ£ `Exploratory Data Analysis`**.\n",
        "\n",
        "> - **4ï¸âƒ£ `Data Visualization of Target Variables`**.\n",
        "\n",
        "> - **5ï¸âƒ£ `Data Preprocessing`**.\n",
        "\n",
        "> - **6ï¸âƒ£ `Splitting our data into Train and Test Subset`**.\n",
        "\n",
        "> - **7ï¸âƒ£ `Transforming Dataset using TF-IDF Vectorizer`**.\n",
        "\n",
        "> - **8ï¸âƒ£ `Function for Model Evaluation`**.\n",
        "\n",
        "> - **9ï¸âƒ£ `Model Building`**.\n",
        "\n",
        "> - **1ï¸âƒ£0ï¸âƒ£ `Conclusion`**."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a6c1a6a4",
      "metadata": {
        "id": "a6c1a6a4"
      },
      "source": [
        "### 1ï¸âƒ£ `Importing the necessary dependencies` :\n",
        "\n",
        "> Here in this part, we import all the necessary libraries that we will use in our project. The choice of libraries depends on the approach we will follow."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f60749c5",
      "metadata": {
        "id": "f60749c5"
      },
      "outputs": [],
      "source": [
        "# utilities : \n",
        "import re # regular expression library\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# plotting :\n",
        "import seaborn as sns\n",
        "from wordcloud import WordCloud\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# nltk :\n",
        "import nltk\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "# sklearn :\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.naive_bayes import BernoulliNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "# time library :\n",
        "import time\n",
        "\n",
        "from google.colab import files\n",
        "from os import environ"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.__version__"
      ],
      "metadata": {
        "id": "wLOIPKyVfIU6"
      },
      "id": "wLOIPKyVfIU6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q kaggle"
      ],
      "metadata": {
        "id": "YAGbEPykFo4T"
      },
      "id": "YAGbEPykFo4T",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "uploaded = files.upload()"
      ],
      "metadata": {
        "id": "sgCGQpInF0nA"
      },
      "id": "sgCGQpInF0nA",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! mkdir ~/.kaggle\n",
        "! cp kaggle.json ~/.kaggle/\n",
        "! chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "dquG2fA_F4Fu"
      },
      "id": "dquG2fA_F4Fu",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! kaggle datasets download -d kazanova/sentiment140"
      ],
      "metadata": {
        "id": "1Q9f4k_6F4_-"
      },
      "id": "1Q9f4k_6F4_-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! unzip /content/sentiment140.zip "
      ],
      "metadata": {
        "id": "ZdFx7qMLF9uF"
      },
      "id": "ZdFx7qMLF9uF",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "37e16165",
      "metadata": {
        "id": "37e16165"
      },
      "source": [
        "### 2ï¸âƒ£ `Reading and Loading the Dataset` :\n",
        "\n",
        "> In any project related to the manipulation and analysis of data, we always start by collecting the data on which we are going to work. In our case, we will import our data from a `.csv` file.\n",
        "\n",
        "The various columns present in the dataset are:\n",
        "- `target`: the polarity of the tweet (positive or negative)\n",
        "- `ids`: Unique id of the tweet\n",
        "- `date`: the date of the tweet\n",
        "- `flag`: It refers to the query. If no such query exists then it is NO QUERY.\n",
        "- `user`: It refers to the name of the user that tweeted\n",
        "- `text`: It refers to the text of the tweet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f26b61a4",
      "metadata": {
        "id": "f26b61a4"
      },
      "outputs": [],
      "source": [
        "# Importing the dataset :\n",
        "DATASET_COLUMNS=['target','ids','date','flag','user','text']\n",
        "DATASET_ENCODING = \"ISO-8859-1\"\n",
        "df = pd.read_csv('/content/training.1600000.processed.noemoticon.csv', encoding=DATASET_ENCODING, names=DATASET_COLUMNS)\n",
        "\n",
        "# Display of the first 5 lines :\n",
        "df.sample(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f23f04ec",
      "metadata": {
        "id": "f23f04ec"
      },
      "source": [
        "### 3ï¸âƒ£ `Exploratory Data Analysis` :\n",
        "> In this part, the objective is to know the imported data as much as possible, we analyze a sample, we look for the shape of the dataset, the column names, the data type information, we check if there are null values, in short, we process our data and above all we target the data (columns) that interests us."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "db0865a1",
      "metadata": {
        "id": "db0865a1"
      },
      "outputs": [],
      "source": [
        "# Display of the first 5 lines of our dataset :\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e15d69e9",
      "metadata": {
        "id": "e15d69e9"
      },
      "outputs": [],
      "source": [
        "# Display the column names of our dataset :\n",
        "df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5bc68e25",
      "metadata": {
        "id": "5bc68e25"
      },
      "outputs": [],
      "source": [
        "# Display the number of records is our dataset :\n",
        "print('length of data is', len(df))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "589c634a",
      "metadata": {
        "scrolled": true,
        "id": "589c634a"
      },
      "outputs": [],
      "source": [
        "df.dtypes"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1260f046",
      "metadata": {
        "id": "1260f046"
      },
      "source": [
        "- The data type of some columns in our dataset is `object`, which means we still have to process our data before getting into machine learning stuff."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "46ada2e4",
      "metadata": {
        "id": "46ada2e4"
      },
      "outputs": [],
      "source": [
        "# Checking for Null values :\n",
        "np.sum(df.isnull().any(axis=1))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "92d6d198",
      "metadata": {
        "id": "92d6d198"
      },
      "source": [
        "- Good news , there are no missing values in our dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0804af11",
      "metadata": {
        "id": "0804af11"
      },
      "outputs": [],
      "source": [
        "# Rows and columns in the dataset :\n",
        "print('Count of columns in the data is:  ', len(df.columns))\n",
        "print('Count of rows in the data is:  ', len(df))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "18bcb030",
      "metadata": {
        "id": "18bcb030"
      },
      "outputs": [],
      "source": [
        "# Checking unique Target Values :\n",
        "df['target'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e5539980",
      "metadata": {
        "id": "e5539980"
      },
      "outputs": [],
      "source": [
        "df['target'].nunique()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f096e22e",
      "metadata": {
        "id": "f096e22e"
      },
      "source": [
        "The **`target`** column is composed of just **0** and **4**\n",
        " - **0** stands for `negative` sentiment.\n",
        " - **4** stands for `positive` sentiment."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6f0002ad",
      "metadata": {
        "id": "6f0002ad"
      },
      "source": [
        "### 4ï¸âƒ£  `Data Visualization of Target Variables` :\n",
        "> After processing our data and targeting the columns we are interested in, the next step is to have a visual on our data with mathematical plots, the reason for using plots is that a plots makes the data speak more, so it become more understandable."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "079ae8d6",
      "metadata": {
        "id": "079ae8d6"
      },
      "outputs": [],
      "source": [
        "df.groupby('target').count()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e9d1ddec",
      "metadata": {
        "id": "e9d1ddec"
      },
      "source": [
        "- Since the **`target`** column only contains **0** or **4**, using the **`.groupby()`** function will result in two categories: **0** and **4**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "779c90d2",
      "metadata": {
        "id": "779c90d2"
      },
      "outputs": [],
      "source": [
        "# Plotting the distribution for dataset :\n",
        "ax = df.groupby('target').count().plot(kind='bar', title='Distribution of data',legend=False)\n",
        "# Naming 0 -> Negative , and 4 -> Positive\n",
        "ax.set_xticklabels(['Negative','Positive'], rotation=0)\n",
        "\n",
        "# Storing data in lists :\n",
        "text, sentiment = list(df['text']), list(df['target'])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aa9e8795",
      "metadata": {
        "id": "aa9e8795"
      },
      "source": [
        "- Each color represents one of the columns : **`ids`**, **`date`**, **`flag`**, **`user`**\tand **`text`**.\n",
        "- **`text`** variable contains the **`text`** column.\n",
        "- **`sentiment`** variable contains the **`target`** column."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d553510a",
      "metadata": {
        "id": "d553510a"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "sns.countplot(x='target', data=df)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aae3ed9b",
      "metadata": {
        "id": "aae3ed9b"
      },
      "source": [
        "- We did the same as before, we just used the **`.countplot()`** function from **`seaborn`**."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "64e688ba",
      "metadata": {
        "id": "64e688ba"
      },
      "source": [
        "### 5ï¸âƒ£  `Data Preprocessing ` :\n",
        "> Before training the model, we will perform various pre-processing steps on the dataset such as: \n",
        ">- Removing stop words.\n",
        ">- Removing emojis. \n",
        ">- Converting the text document to lowercase for better generalization.\n",
        ">- Cleaning the ponctuation (to reduce unnecessary noise from the dataset).\n",
        ">- Removing the repeating characters from the words along with removing the URLs as they do not have any significant importance. <br>                          \n",
        "and much more, we will see this in detail later...\n",
        "\n",
        "> We will then performe \n",
        ">- **`Stemming`** : reducing the words to their derived stems.\n",
        ">- **`Lemmatization`** : reducing the derived words to their root form known as lemma for better results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c6c00829",
      "metadata": {
        "id": "c6c00829"
      },
      "outputs": [],
      "source": [
        "# Selecting the text and Target column for our further analysis :\n",
        "data = df[['text','target']]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0e981da0",
      "metadata": {
        "id": "0e981da0"
      },
      "source": [
        "- **`data`** variable contains the **`target`** and **`text`** columns."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8bafa317",
      "metadata": {
        "id": "8bafa317"
      },
      "outputs": [],
      "source": [
        "# Replacing the values to ease understanding :\n",
        "data['target'] = data['target'].replace(4,1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c009baa6",
      "metadata": {
        "id": "c009baa6"
      },
      "outputs": [],
      "source": [
        "# Print unique values of target variable :\n",
        "data['target'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test example \n",
        "d_d = {'text': ['I want to hit you with a rock for what you hava just said', \n",
        "              'I really appreciate that you shared with me with your thoughts about a situation, so do not worry about that I would never hit you with anything for that genle thing you have made',\n",
        "              'I like potato and meat',\n",
        "              'I hate coca-cola',\n",
        "              'I am sick of travelling alone',\n",
        "              'Some teachers have maniac idea to give to students as many homework as possible. It is hard to deal with them',\n",
        "              'Many friends of my girlfriend complain too much about everything, it is so annoying',\n",
        "              'My friends are too strong and clever they always have a good mood and ready work hard',\n",
        "              'I am happy to study in this city, it is so enormous and convenient',\n",
        "              'I love quite places like the morning on a lake'\n",
        "              ],\n",
        "       'target': [0, 1, 1, 0,0,0, 0, 1, 1, 1]}\n",
        "df_d = pd.DataFrame(data=d_d)\n",
        "print(df_d)\n",
        "df_d.to_csv('data_example.csv', index=False)"
      ],
      "metadata": {
        "id": "2rG4vSMrNMyJ"
      },
      "id": "2rG4vSMrNMyJ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "fb1b79d5",
      "metadata": {
        "id": "fb1b79d5"
      },
      "source": [
        "The **`target`** column is composed of just **0** and **1**\n",
        " - **0** stands for **`negative`** sentiment.\n",
        " - **1** stands for **`positive`** sentiment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c5f6157b",
      "metadata": {
        "id": "c5f6157b"
      },
      "outputs": [],
      "source": [
        "# Separating positive and negative tweets :\n",
        "data_pos = data[data['target'] == 1]\n",
        "data_neg = data[data['target'] == 0]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3f0040ca",
      "metadata": {
        "id": "3f0040ca"
      },
      "source": [
        " - The **`data_pos`** variable contains the **`text`** and the **`target = 1`** columns. \n",
        " - The **`data_neg`** variable contains the **`text`** and the **`target = 0`** columns. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ee5fb163",
      "metadata": {
        "id": "ee5fb163"
      },
      "outputs": [],
      "source": [
        "# Combining positive and negative tweets :\n",
        "dataset = pd.concat([data_pos, data_neg])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4a150167",
      "metadata": {
        "id": "4a150167"
      },
      "source": [
        "- The **`dataset`** variable is a pandas dataframe **(1600000 rows x 2 columns)** that contains the **`text`** and the **`target`** columns. \n",
        "- The **800000** first rows are the positive tweets.\n",
        "- The **800000** second rows are the negative tweets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8c48c42c",
      "metadata": {
        "id": "8c48c42c"
      },
      "outputs": [],
      "source": [
        "# Quick view of how our data looks:\n",
        "dataset['text'].tail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "af8a4522",
      "metadata": {
        "id": "af8a4522"
      },
      "outputs": [],
      "source": [
        "# Making statement text in lower case :\n",
        "dataset['text'] = dataset['text'].str.lower()\n",
        "dataset['text'].tail()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "93bbd79d",
      "metadata": {
        "id": "93bbd79d"
      },
      "source": [
        "- **`text`** column is made up of only lowercase characters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aa0b3ef1",
      "metadata": {
        "id": "aa0b3ef1"
      },
      "outputs": [],
      "source": [
        "# Defining set containing all stopwords in English :\n",
        "stopwordlist = ['a', 'about', 'above', 'after', 'again', 'ain', 'all', 'am', 'an',\n",
        "                'and', 'any', 'are', 'as', 'at', 'be', 'because', 'been', 'before',\n",
        "                'being', 'below', 'between', 'both', 'by', 'can', 'd', 'did', 'do',\n",
        "                'does', 'doing', 'down', 'during', 'each', 'few', 'for', 'from',\n",
        "                'further', 'had', 'has', 'have', 'having', 'he', 'her', 'here',\n",
        "                'hers', 'herself', 'him', 'himself', 'his', 'how', 'i', 'if', 'in',\n",
        "                'into', 'is', 'it', 'its', 'itself', 'just', 'll', 'm', 'ma',\n",
        "                'me', 'more', 'most', 'my', 'myself', 'now', 'o', 'of', 'on', 'once',\n",
        "                'only', 'or', 'other', 'our', 'ours', 'ourselves', 'out', 'own', 're',\n",
        "                's', 'same', 'she', \"shes\", 'should', \"shouldve\", 'so', 'some', 'such',\n",
        "                't', 'than', 'that', \"thatll\", 'the', 'their', 'theirs', 'them',\n",
        "                'themselves', 'then', 'there', 'these', 'they', 'this', 'those',\n",
        "                'through', 'to', 'too', 'under', 'until', 'up', 've', 'very', 'was',\n",
        "                'we', 'were', 'what', 'when', 'where', 'which', 'while', 'who', 'whom',\n",
        "                'why', 'will', 'with', 'won', 'y', 'you', \"youd\", \"youll\", \"youre\",\n",
        "                \"youve\", 'your', 'yours', 'yourself', 'yourselves']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7e4469a8",
      "metadata": {
        "id": "7e4469a8"
      },
      "outputs": [],
      "source": [
        "# Cleaning and removing the above stop words list from the tweet text :\n",
        "STOPWORDS = set(stopwordlist)\n",
        "\n",
        "\n",
        "def cleaning_stopwords(text):\n",
        "    return \" \".join([word for word in str(text).split() if word not in STOPWORDS])\n",
        "\n",
        "\n",
        "dataset['text'] = dataset['text'].apply(lambda text: cleaning_stopwords(text))\n",
        "dataset['text'].head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e1aec7cb",
      "metadata": {
        "id": "e1aec7cb"
      },
      "source": [
        "- **`text`** column has been cleaned of stop words."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "58d36afa",
      "metadata": {
        "id": "58d36afa"
      },
      "outputs": [],
      "source": [
        "#  Cleaning and removing punctuations :\n",
        "import string\n",
        "\n",
        "english_punctuations = string.punctuation\n",
        "punctuations_list = english_punctuations\n",
        "\n",
        "\n",
        "def cleaning_punctuations(text):\n",
        "    translator = str.maketrans('', '', punctuations_list)\n",
        "    return text.translate(translator)\n",
        "\n",
        "\n",
        "dataset['text'] = dataset['text'].apply(lambda x: cleaning_punctuations(x))\n",
        "dataset['text'].tail()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "942797ec",
      "metadata": {
        "id": "942797ec"
      },
      "source": [
        "- **`text`** column has been cleaned of punctuation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fef1ba23",
      "metadata": {
        "id": "fef1ba23"
      },
      "outputs": [],
      "source": [
        "# Cleaning and removing URLâ€™s :\n",
        "def cleaning_URLs(data):\n",
        "    return re.sub('((www.[^s]+)|(https?://[^s]+))', ' ', data)\n",
        "\n",
        "\n",
        "dataset['text'] = dataset['text'].apply(lambda x: cleaning_URLs(x))\n",
        "dataset['text'].tail()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a0854ac1",
      "metadata": {
        "id": "a0854ac1"
      },
      "source": [
        "- **`text`** column has now been cleaned of URLs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e99297b6",
      "metadata": {
        "id": "e99297b6"
      },
      "outputs": [],
      "source": [
        "# Cleaning and removing Numeric numbers :\n",
        "def cleaning_numbers(data):\n",
        "    return re.sub('[0-9]+', '', data)\n",
        "dataset['text'] = dataset['text'].apply(lambda x: cleaning_numbers(x))\n",
        "dataset['text'].tail()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "57116704",
      "metadata": {
        "id": "57116704"
      },
      "source": [
        "- Column **`text`** has now been cleaned of numeric numbers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7220de55",
      "metadata": {
        "id": "7220de55"
      },
      "outputs": [],
      "source": [
        "# Getting tokenization of tweet text :\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "dataset['text'] = dataset['text'].apply(word_tokenize)\n",
        "dataset['text'].head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9b7fd110",
      "metadata": {
        "id": "9b7fd110"
      },
      "source": [
        "- Column **`text`** has now been tokenized."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "08bd3c4a",
      "metadata": {
        "id": "08bd3c4a"
      },
      "outputs": [],
      "source": [
        "# Applying Stemming :\n",
        "st = nltk.PorterStemmer()\n",
        "\n",
        "def stemming_on_text(data):\n",
        "    text = [st.stem(word) for word in data]\n",
        "    return text\n",
        "\n",
        "dataset['text'] = dataset['text'].apply(lambda x: stemming_on_text(x))\n",
        "dataset['text'].head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ff3e7dc8",
      "metadata": {
        "id": "ff3e7dc8"
      },
      "source": [
        "- **Stemming** has now been applied to the **`text`** column."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3c3dc360",
      "metadata": {
        "id": "3c3dc360"
      },
      "outputs": [],
      "source": [
        "# Applying Lemmatizer :\n",
        "lm = nltk.WordNetLemmatizer()\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "def lemmatizer_on_text(data):\n",
        "    text = [lm.lemmatize(word) for word in data]\n",
        "    return text\n",
        "\n",
        "dataset['text'] = dataset['text'].apply(lambda x: lemmatizer_on_text(x))\n",
        "dataset['text'].head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "54aa1810",
      "metadata": {
        "id": "54aa1810"
      },
      "source": [
        "- **Lemmatizer** has now been applied to the **`text`** column."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8d516d12",
      "metadata": {
        "id": "8d516d12"
      },
      "outputs": [],
      "source": [
        "# Separating input feature and label :\n",
        "X = data.text\n",
        "y = data.target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a6405266",
      "metadata": {
        "scrolled": false,
        "id": "a6405266"
      },
      "outputs": [],
      "source": [
        "# Plot a cloud of words for negative tweets :\n",
        "data_neg = data['text'][:800000] # selecting the negative tweets.\n",
        "plt.figure(figsize=(20, 20))\n",
        "wc = WordCloud(max_words=1000, width=1600, height=800,\n",
        "               collocations=False).generate(\" \".join(data_neg))\n",
        "plt.imshow(wc)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e9473d5c",
      "metadata": {
        "id": "e9473d5c"
      },
      "source": [
        "- As the picture shows, a lot of negative words appear: bad, sad, wrong.."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "826a5563",
      "metadata": {
        "id": "826a5563"
      },
      "outputs": [],
      "source": [
        "# Plot a cloud of words for positive tweets :\n",
        "data_pos = data['text'][800000:]  # selecting the positive tweets.\n",
        "wc = WordCloud(max_words=1000, width=1600, height=800,\n",
        "               collocations=False).generate(\" \".join(data_pos))\n",
        "plt.figure(figsize=(20, 20))\n",
        "plt.imshow(wc)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "47e5d0b0",
      "metadata": {
        "id": "47e5d0b0"
      },
      "source": [
        "- As the picture shows, a lot of negative words appear: good, love, happy.."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e9fec75b",
      "metadata": {
        "id": "e9fec75b"
      },
      "source": [
        "### 6ï¸âƒ£  `Splitting our data into Train and Test Subset ` :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "41bf22d6",
      "metadata": {
        "id": "41bf22d6"
      },
      "outputs": [],
      "source": [
        "# Separating the 95% data for training data and 5% for testing data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.05, random_state=26105111)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "61a41a66",
      "metadata": {
        "id": "61a41a66"
      },
      "source": [
        "- **`random_state`** is basically used for reproducing your problem the same every time it is run. If we do not use a **random_state** in **train_test_split**, every time you make the split we might get a different set of train and test data points and will not help in debugging in case we get an issue.\n",
        "\n",
        "- **`X`** contains **`data.text`**\n",
        "- **`y`** contains = **`data.target`**\n",
        "\n",
        "\n",
        "- **`X_train`** contains **95%** of **`data.text`**\n",
        "- **`X_test`** contains **5%** of **`data.text`**\n",
        "\n",
        "\n",
        "- **`y_train`** contains **95%** of **`data.target`**\n",
        "- **`y_test`** contains **5%** of **`data.target`**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ac7a96a2",
      "metadata": {
        "id": "ac7a96a2"
      },
      "source": [
        "###  7ï¸âƒ£ `Transforming Dataset using TF-IDF Vectorizer` :\n",
        "> Scikit-learn's **`Tfidftransformer`** and **`Tfidfvectorizer`** aim to do the same thing, which is to convert a collection of raw documents to a matrix of **TF-IDF features**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d7ff5ed2",
      "metadata": {
        "id": "d7ff5ed2"
      },
      "outputs": [],
      "source": [
        "# Fit the TF-IDF Vectorizer :\n",
        "vectoriser = TfidfVectorizer(ngram_range=(1,2), max_features=500000)\n",
        "vectoriser.fit(X_train)\n",
        "print('No. of feature_words: ', len(vectoriser.get_feature_names_out() ))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a4239a6b",
      "metadata": {
        "id": "a4239a6b"
      },
      "outputs": [],
      "source": [
        "# Transform the data using TF-IDF Vectorizer :\n",
        "X_train = vectoriser.transform(X_train)\n",
        "X_test  = vectoriser.transform(X_test)\n",
        "X_test"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X"
      ],
      "metadata": {
        "id": "Ksornfp9UiWa"
      },
      "id": "Ksornfp9UiWa",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train)"
      ],
      "metadata": {
        "id": "qucG1iXxB4Pg"
      },
      "id": "qucG1iXxB4Pg",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train"
      ],
      "metadata": {
        "id": "RQCWPetGB1zQ"
      },
      "id": "RQCWPetGB1zQ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "215e1e03",
      "metadata": {
        "id": "215e1e03"
      },
      "source": [
        "###  8ï¸âƒ£ `Function for Model Evaluation` :\n",
        "> After training the model we then apply the evaluation measures to check how the model is performing. Accordingly, we use the following evaluation parameters to check the performance of the models respectively :\n",
        "> - **`Accuracy Score`** : Typically, the accuracy of a predictive model is good (above 90% accuracy)\n",
        "> - **`ROC-AUC Curve`** : The Area Under the Curve (AUC) is the measure of the ability of a classifier to distinguish between classes and is used as a summary of the ROC curve. The higher the AUC, the better the performance of the model at distinguishing between the positive and negative classes.\n",
        "> - **`Confusion Matrix with Plot`** : A Confusion matrix is an N x N matrix used for evaluating the performance of a classification model, where N is the number of target classes. The matrix compares the actual target values with those predicted by the machine learning model.\n",
        "    * **`Actual values`** are the columns.\n",
        "    * **`Predicted values`** are the lines.\n",
        "><table>\n",
        "    <tbody>\n",
        "        <tr>\n",
        "            <td></td>\n",
        "            <td><b>Positive</b></td>\n",
        "            <td><b>Negative</b></td>\n",
        "        </tr>\n",
        "        <tr>\n",
        "            <td><b>Positive</b></td>\n",
        "            <td>TP</td>\n",
        "            <td>TN</td>\n",
        "        </tr>\n",
        "        <tr>\n",
        "            <td><b>Negative</b></td>\n",
        "            <td>FP</td>\n",
        "            <td>TN</td>\n",
        "        </tr>\n",
        "    </tbody>\n",
        "</table> \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "61c31f2e",
      "metadata": {
        "id": "61c31f2e"
      },
      "outputs": [],
      "source": [
        "def model_Evaluate(model):\n",
        "    # Predict values for Test dataset\n",
        "    y_pred = model.predict(X_test)\n",
        "    # Print the evaluation metrics for the dataset.\n",
        "    print(classification_report(y_test, y_pred))\n",
        "    # Compute and plot the Confusion matrix\n",
        "    cf_matrix = confusion_matrix(y_test, y_pred)\n",
        "    categories = ['Negative','Positive']\n",
        "    group_names = ['True Neg','False Pos', 'False Neg','True Pos']\n",
        "    group_percentages = ['{0:.2%}'.format(value) for value in cf_matrix.flatten() / np.sum(cf_matrix)]\n",
        "    labels = [f'{v1}n{v2}' for v1, v2 in zip(group_names,group_percentages)]\n",
        "    labels = np.asarray(labels).reshape(2,2)\n",
        "    sns.heatmap(cf_matrix, annot = labels, cmap = 'Blues',fmt = '',\n",
        "    xticklabels = categories, yticklabels = categories)\n",
        "    plt.xlabel(\"Predicted values\", fontdict = {'size':14}, labelpad = 10)\n",
        "    plt.ylabel(\"Actual values\" , fontdict = {'size':14}, labelpad = 10)\n",
        "    plt.title (\"Confusion Matrix\", fontdict = {'size':18}, pad = 20)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pattern = r'\\.?\\w+'\n",
        "s = 'data_example.csv'\n",
        "find_sp = re.findall(pattern, s)\n",
        "name, suffix = find_sp[0], find_sp[1]"
      ],
      "metadata": {
        "id": "2-nqbmPhDguN"
      },
      "id": "2-nqbmPhDguN",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "2edadbc6",
      "metadata": {
        "id": "2edadbc6"
      },
      "source": [
        "- To avoid each time and for each model, drawing the confusion matrix, printing the precision, the f1-score... we just define the **`model Evaluate()`** function which will do the job each time."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f32443c0",
      "metadata": {
        "id": "f32443c0"
      },
      "source": [
        "###  9ï¸âƒ£ `Model Building` :\n",
        "> In the problem statement we have used three different models respectively :\n",
        ">- **`Bernoulli Naive Bayes`**.\n",
        ">- **`SVM (Support Vector Machine)`**.\n",
        ">- **`Logistic Regression`**.\n",
        "\n",
        ">The idea behind choosing these models is that **we want to try all the classifiers on the dataset** ranging from simple models to complex models, and try to **find the one that performs the best**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4e556337",
      "metadata": {
        "id": "4e556337"
      },
      "outputs": [],
      "source": [
        "# Model-1 : Bernoulli Naive Bayes.\n",
        "BNBmodel = BernoulliNB()\n",
        "start = time.time()\n",
        "BNBmodel.fit(X_train, y_train)\n",
        "end = time.time()\n",
        "print(\"The execution time of this model is {:.2f} seconds\\n\".format(end-start))\n",
        "model_Evaluate(BNBmodel)\n",
        "y_pred1 = BNBmodel.predict(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "38ca5cc8",
      "metadata": {
        "id": "38ca5cc8"
      },
      "source": [
        "- The **`class 0`** is the class of **negative tweets**.\n",
        "- The **`class 1`** is the class of **positive tweets**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cee3c32b",
      "metadata": {
        "id": "cee3c32b"
      },
      "outputs": [],
      "source": [
        "# Plot the ROC-AUC Curve for model-1 :\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "fpr, tpr, thresholds = roc_curve(y_test, y_pred1)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "plt.figure()\n",
        "plt.plot(fpr, tpr, color='darkorange', lw=1, label='ROC curve (area = %0.2f)' % roc_auc)\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC CURVE')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2541cea0",
      "metadata": {
        "id": "2541cea0"
      },
      "outputs": [],
      "source": [
        "# Model-2 : SVM (Support Vector Machine).\n",
        "SVCmodel = LinearSVC()\n",
        "start = time.time()\n",
        "SVCmodel.fit(X_train, y_train)\n",
        "end = time.time()\n",
        "print(\"The execution time of this model is {:.2f} seconds\\n\".format(end-start))\n",
        "model_Evaluate(SVCmodel)\n",
        "y_pred2 = SVCmodel.predict(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "45a2eb34",
      "metadata": {
        "id": "45a2eb34"
      },
      "source": [
        "- The **`class 0`** is the class of **negative tweets**.\n",
        "- The **`class 1`** is the class of **positive tweets**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "72332e7b",
      "metadata": {
        "id": "72332e7b"
      },
      "outputs": [],
      "source": [
        "# Plot the ROC-AUC Curve for model-2 :\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "fpr, tpr, thresholds = roc_curve(y_test, y_pred2)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "plt.figure()\n",
        "plt.plot(fpr, tpr, color='darkorange', lw=1, label='ROC curve (area = %0.2f)' % roc_auc)\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC CURVE')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d2640045",
      "metadata": {
        "id": "d2640045"
      },
      "outputs": [],
      "source": [
        "# Model-3 : Logistic Regression.\n",
        "LRmodel = LogisticRegression(C = 2, max_iter = 1000, n_jobs=-1)\n",
        "start = time.time()\n",
        "LRmodel.fit(X_train, y_train)\n",
        "end = time.time()\n",
        "print(\"The execution time of this model is {:.2f} seconds\\n\".format(end-start))\n",
        "model_Evaluate(LRmodel)\n",
        "y_pred3 = LRmodel.predict(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bfd912c0",
      "metadata": {
        "id": "bfd912c0"
      },
      "source": [
        "- The **`class 0`** is the class of **negative tweets**.\n",
        "- The **`class 1`** is the class of **positive tweets**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8f0795b5",
      "metadata": {
        "id": "8f0795b5"
      },
      "outputs": [],
      "source": [
        "# Plot the ROC-AUC Curve for model-3 :\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "fpr, tpr, thresholds = roc_curve(y_test, y_pred3)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "plt.figure()\n",
        "plt.plot(fpr, tpr, color='darkorange', lw=1, label='ROC curve (area = %0.2f)' % roc_auc)\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC CURVE')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3f752c46",
      "metadata": {
        "id": "3f752c46"
      },
      "source": [
        "###  1ï¸âƒ£0ï¸âƒ£ `Conclusion` :\n",
        "> After evaluating all models, we can conclude the following details :\n",
        "><table>\n",
        "    <thead>\n",
        "        <tr>\n",
        "            <th><b>Model</b></th>\n",
        "            <th><b>Accuracy</b></th>\n",
        "            <th><b>F1-score ( class 0 )</b></th>\n",
        "            <th><b>F1-score ( class 1 )</b></th>\n",
        "            <th><b>AUC Score</b></th>\n",
        "            <th><b>Execution time</b></th>\n",
        "        </tr>\n",
        "        </thead>\n",
        "    <tbody>\n",
        "        <tr>\n",
        "            <td><b>Bernoulli Naive Bayes (BNB)</b></td>\n",
        "            <td>80%</td> \n",
        "            <td>80%</td>\n",
        "            <td>80%</td>\n",
        "            <td>80%</td>\n",
        "            <td>0.69 seconds</td>\n",
        "        </tr>\n",
        "        <tr>\n",
        "            <td><b>Support Vector Machine (SVM)</b></td>\n",
        "            <td>82%</td> \n",
        "            <td>81%</td>\n",
        "            <td>82%</td>\n",
        "            <td>82%</td>\n",
        "            <td>28.32 seconds</td>\n",
        "        </tr>\n",
        "        <tr>\n",
        "            <td><b>Logistic Regression (LR)</b></td>\n",
        "            <td>83%</td> \n",
        "            <td>83%</td>\n",
        "            <td>83%</td>\n",
        "            <td>83%</td>\n",
        "            <td>163.56 seconds</td>\n",
        "        </tr>\n",
        "    </tbody>\n",
        "</table>\n",
        "\n",
        "\n",
        " - **`Execution time`** : When it comes to comparing the running time of models, `Bernoulli Naive Bayes` performs faster than `SVM`, which in turn runs faster than `Logistic Regression`.\n",
        " - **`Accuracy`** : When it comes to model accuracy, `logistic regression` performs better than `SVM`, which in turn performs better than `Bernoulli Naive Bayes`.\n",
        " - **`F1-score`** : The F1 Scores for **class 0** and **class 1** are :\n",
        "> - For **class 0** (negative tweets) : \n",
        ">```\n",
        "accuracy : BNB (= 0.80) < SVM (=0.81) < LR (= 0.83) \n",
        ">``` \n",
        "> - For **class 1** (positive tweets) : \n",
        ">```\n",
        "accuracy : BNB (= 0.80) < SVM (=0.82) < LR (= 0.83) \n",
        ">```\n",
        " - **`AUC Score`** : All three models have the same ROC-AUC score.\n",
        ">```\n",
        "AUC score : BNB (= 0.80) < SVM (=0.82) < LR (= 0.83) \n",
        ">``` \n",
        "\n",
        "- We therefore conclude that **`logistic regression`** is the **best model** for the above dataset.(although it took much longer to run than other models).                           \n",
        "\n",
        "\n",
        "- In our problem statement, **`logistic regression`** follows **`Occam's razor principle`** which defines that for a particular problem statement, if the data has no assumptions, then the simplest model works best. Since our **dataset has no assumptions** and **logistic regression is a simple model**, so the concept holds true for the dataset mentioned above."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e8d9bf65",
      "metadata": {
        "id": "e8d9bf65"
      },
      "source": [
        "Notebook realised by  [@labriji_saad](https://github.com/labrijisaad) with the help of [analyticsvidhya](https://www.analyticsvidhya.com/)."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "tuj6P-Frhod7"
      },
      "id": "tuj6P-Frhod7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filename_V = '/content/drive/MyDrive/Big_data/First_lab/Models_weights/Vectoriser.pickle'\n",
        "pickle.dump(vectoriser, open(filename_V, 'wb'))"
      ],
      "metadata": {
        "id": "3co-oD9HQPoj"
      },
      "id": "3co-oD9HQPoj",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filename_LR = '/content/drive/MyDrive/Big_data/First_lab/Models_weights/LR.pickle'\n",
        "pickle.dump(LRmodel, open(filename_LR, 'wb'))\n",
        "\n",
        "filename_SVM = '/content/drive/MyDrive/Big_data/First_lab/Models_weights/SVM.pickle'\n",
        "pickle.dump(SVCmodel, open(filename_SVM, 'wb'))\n",
        "\n",
        "filename_BNB = '/content/drive/MyDrive/Big_data/First_lab/Models_weights/BNB.pickle'\n",
        "pickle.dump(BNBmodel, open(filename_BNB, 'wb'))"
      ],
      "metadata": {
        "id": "B51T1BYyhqwb"
      },
      "id": "B51T1BYyhqwb",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loaded_model_LR = pickle.load(open(filename_LR, 'rb'))\n",
        "loaded_model_SVM = pickle.load(open(filename_SVM, 'rb'))\n",
        "loaded_model_BNB = pickle.load(open(filename_BNB, 'rb'))"
      ],
      "metadata": {
        "id": "vTm-xkYRiNSl"
      },
      "id": "vTm-xkYRiNSl",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filename_X_train = '/content/drive/MyDrive/Big_data/First_lab/data/X_train_vectorised.pickle'\n",
        "pickle.dump(X_train, open(filename_X_train, 'wb'))\n",
        "\n",
        "filename_X_test = '/content/drive/MyDrive/Big_data/First_lab/data/X_test_vectorised.pickle'\n",
        "pickle.dump(X_test, open(filename_X_test, 'wb'))\n",
        "\n",
        "filename_y_train = '/content/drive/MyDrive/Big_data/First_lab/data/y_train_vectorised.pickle'\n",
        "pickle.dump(y_train, open(filename_y_train, 'wb'))\n",
        "\n",
        "filename_y_test = '/content/drive/MyDrive/Big_data/First_lab/data/y_test_vectorised.pickle'\n",
        "pickle.dump(y_test, open(filename_y_test, 'wb'))"
      ],
      "metadata": {
        "id": "ymhyM8exiRVl"
      },
      "id": "ymhyM8exiRVl",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = pickle.load(open(filename_X_train, 'rb'))\n",
        "X_test = pickle.load(open(filename_X_test, 'rb'))\n",
        "y_train = pickle.load(open(filename_y_train, 'rb'))\n",
        "y_test = pickle.load(open(filename_y_test, 'rb'))"
      ],
      "metadata": {
        "id": "LYFl6mwwkfje"
      },
      "id": "LYFl6mwwkfje",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BNBmodel = BernoulliNB()\n",
        "start = time.time()\n",
        "BNBmodel.fit(X_train, y_train)\n",
        "end = time.time()\n",
        "print(\"The execution time of this model is {:.2f} seconds\\n\".format(end-start))\n",
        "model_Evaluate(BNBmodel)\n",
        "y_pred1 = BNBmodel.predict(X_test)"
      ],
      "metadata": {
        "id": "t-4BjO98k-qR"
      },
      "id": "t-4BjO98k-qR",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SaSWdvB3mdOa"
      },
      "id": "SaSWdvB3mdOa",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}